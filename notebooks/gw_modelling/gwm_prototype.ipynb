{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of geographically weighted random forest classification modelling\n",
    "\n",
    "To-do:\n",
    "- [x] global model\n",
    "- [x] model evaluation\n",
    "- [x] bandwidth optimisation\n",
    "- [x] feature importances\n",
    "- [x] golden section bandwidth selection\n",
    "- [x] other metrics than accuracy\n",
    "- [x] generic support (logistic regression, gradient boosting)\n",
    "- [ ] local performance of models that do not support OOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import geopandas as gpd\n",
    "from libpysal import graph\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from geodatasets import get_path\n",
    "from joblib import Parallel, delayed\n",
    "from typing import Hashable, Callable\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn import metrics, preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(get_path(\"geoda.ncovr\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is in the geographic coords in the  US and we need to work with distances. Re-project and use only points as the graph builder will require points anyway.\n",
    "gdf = gdf.set_geometry(gdf.representative_point()).to_crs(5070)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a base class for the heavy lifting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _triangular(distances, bandwidth):\n",
    "    u = np.clip(distances / bandwidth, 0, 1)\n",
    "    return 1 - u\n",
    "\n",
    "\n",
    "def _parabolic(distances, bandwidth):\n",
    "    u = np.clip(distances / bandwidth, 0, 1)\n",
    "    return 0.75 * (1 - u**2)\n",
    "\n",
    "\n",
    "def _gaussian(distances, bandwidth):\n",
    "    u = distances / bandwidth\n",
    "    return np.exp(-((u / 2) ** 2)) / (np.sqrt(2) * np.pi)\n",
    "\n",
    "\n",
    "def _bisquare(distances, bandwidth):\n",
    "    u = np.clip(distances / bandwidth, 0, 1)\n",
    "    return (15 / 16) * (1 - u**2) ** 2\n",
    "\n",
    "\n",
    "def _cosine(distances, bandwidth):\n",
    "    u = np.clip(distances / bandwidth, 0, 1)\n",
    "    return (np.pi / 4) * np.cos(np.pi / 2 * u)\n",
    "\n",
    "\n",
    "def _exponential(distances, bandwidth):\n",
    "    u = distances / bandwidth\n",
    "    return np.exp(-u)\n",
    "\n",
    "\n",
    "def _boxcar(distances, bandwidth):\n",
    "    r = (distances < bandwidth).astype(int)\n",
    "    return r\n",
    "\n",
    "\n",
    "_kernel_functions = {\n",
    "    \"triangular\": _triangular,\n",
    "    \"parabolic\": _parabolic,\n",
    "    \"gaussian\": _gaussian,\n",
    "    \"bisquare\": _bisquare,\n",
    "    \"cosine\": _cosine,\n",
    "    \"boxcar\": _boxcar,\n",
    "    \"exponential\": _exponential,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Classification only at the moment due to hard-coded accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GWM:\n",
    "    \"\"\"Generic geographically weighted modelling meta-class\n",
    "\n",
    "    NOTE: local models leave out focal, unlike in traditional approaches. This allows\n",
    "    assessment of geographically weighted metrics on unseen data without a need for\n",
    "    train/test split, hence providing value for all samples. This is needed for\n",
    "    futher spatial analysis of the model performance (and generalises to models\n",
    "    that do not support OOB scoring).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :  model class\n",
    "        Scikit-learn model class\n",
    "    bandwidth : int | float\n",
    "        bandwidth value consisting of either a distance or N nearest neighbors\n",
    "    fixed : bool, optional\n",
    "        True for distance based bandwidth and False for adaptive (nearest neighbor) bandwidth, by default False\n",
    "    kernel : str, optional\n",
    "        type of kernel function used to weight observations, by default \"bisquare\"\n",
    "    n_jobs : int, optional\n",
    "        The number of jobs to run in parallel. ``-1`` means using all processors by default ``-1``\n",
    "    fit_global_model : bool, optional\n",
    "        Determines if the global baseline model shall be fitted alognside the geographically weighted, by default True\n",
    "    strict : bool, optional\n",
    "        Do not fit any models if at least one neighborhood has invariant ``y``, by default False\n",
    "    keep_models : bool, optional\n",
    "        Keep all local models (required for prediction), by default True. Note that for some models,\n",
    "        like random forests, the objects can be large.\n",
    "    **kwargs\n",
    "        Additional keyword arguments passed to ``model`` initialisation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        bandwidth: int | float,\n",
    "        fixed: bool = False,\n",
    "        kernel: str | Callable = \"bisquare\",\n",
    "        n_jobs: int = -1,\n",
    "        fit_global_model: bool = True,\n",
    "        measure_performance: bool = True,\n",
    "        strict: bool = False,\n",
    "        keep_models: bool = False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.bandwidth = bandwidth\n",
    "        self.kernel = kernel\n",
    "        self.fixed = fixed\n",
    "        self.model_kwargs = kwargs\n",
    "        self.n_jobs = n_jobs\n",
    "        self.fit_global_model = fit_global_model\n",
    "        self.measure_performance = measure_performance\n",
    "        self.strict = strict\n",
    "        self.keep_models = keep_models\n",
    "        self._measure_oob = \"oob_score\" in inspect.signature(model).parameters\n",
    "        if self._measure_oob:\n",
    "            self.model_kwargs[\"oob_score\"] = self._accuracy_data\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series, geometry: gpd.GeoSeries):\n",
    "        \"\"\"Fit the geographically weighted model\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd.DataFrame\n",
    "            Independent variables\n",
    "        y : pd.Series\n",
    "            Dependent variable\n",
    "        geometry : gpd.GeoSeries\n",
    "            Geographic location\n",
    "        \"\"\"\n",
    "        # build graph\n",
    "        if self.fixed:  # fixed distance\n",
    "            self.weights = graph.Graph.build_kernel(\n",
    "                geometry, kernel=self.kernel, bandwidth=self.bandwidth\n",
    "            )\n",
    "        else:  # adaptive KNN\n",
    "            weights = graph.Graph.build_kernel(\n",
    "                geometry, kernel=\"identity\", k=self.bandwidth\n",
    "            )\n",
    "            # post-process identity weights by the selected kernel\n",
    "            # and kernel bandwidth derived from each neighborhood\n",
    "            bandwidth = weights._adjacency.groupby(level=0).transform(\"max\")\n",
    "            self.weights = graph.Graph(\n",
    "                adjacency=_kernel_functions[self.kernel](weights._adjacency, bandwidth),\n",
    "                is_sorted=True,\n",
    "            )\n",
    "\n",
    "        # fit the models\n",
    "        data = X.copy()\n",
    "        data[\"_y\"] = y\n",
    "        data = data.loc[self.weights._adjacency.index.get_level_values(1)]\n",
    "        data[\"_weight\"] = self.weights._adjacency.values\n",
    "        grouper = data.groupby(self.weights._adjacency.index.get_level_values(0))\n",
    "\n",
    "        if self.strict:\n",
    "            invariant = (\n",
    "                data[\"_y\"]\n",
    "                .groupby(self.weights._adjacency.index.get_level_values(0))\n",
    "                .nunique()\n",
    "                == 1\n",
    "            )\n",
    "            if invariant.any():\n",
    "                raise ValueError(\n",
    "                    f\"y at locations {invariant.index[invariant]} is invariant.\"\n",
    "                )\n",
    "\n",
    "        # models are fit in parallel\n",
    "        traning_output = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(self._fit_local)(\n",
    "                self.model, group, name, focal_x, self.model_kwargs, self.keep_models\n",
    "            )\n",
    "            for (name, group), focal_x in zip(grouper, X.values)\n",
    "        )\n",
    "        if self.keep_models:\n",
    "            names, oob_accuracy_data, feature_importances, focal_proba, models = zip(\n",
    "                *traning_output\n",
    "            )\n",
    "            self.local_models = pd.Series(models, index=names)\n",
    "        else:\n",
    "            names, oob_accuracy_data, feature_importances, focal_proba = zip(\n",
    "                *traning_output\n",
    "            )\n",
    "\n",
    "        self.focal_proba_ = pd.DataFrame(focal_proba).fillna(0).loc[:, np.unique(y)]\n",
    "\n",
    "        if self.fit_global_model:\n",
    "            if self._measure_oob:\n",
    "                self.model_kwargs[\"oob_score\"] = True\n",
    "            # fit global model as a baseline\n",
    "            self.global_model = self.model(n_jobs=self.n_jobs, **self.model_kwargs)\n",
    "            self.global_model.fit(X=X, y=y)\n",
    "\n",
    "        if self.measure_performance:\n",
    "            # global GW accuracy\n",
    "            focal_pred = self.focal_proba_.idxmax(axis=1)\n",
    "            self.score_ = metrics.accuracy_score(y, focal_pred)\n",
    "            self.f1_macro = metrics.f1_score(y, focal_pred, average=\"macro\")\n",
    "            self.f1_micro = metrics.f1_score(y, focal_pred, average=\"micro\")\n",
    "            self.f1_weighted = metrics.f1_score(y, focal_pred, average=\"weighted\")\n",
    "\n",
    "            # OOB accuracy (if model allows)\n",
    "            if self._measure_oob:\n",
    "                true, n = zip(*oob_accuracy_data)\n",
    "                self.oob_score_ = sum(true) / sum(n)\n",
    "                self.local_oob_score_ = pd.Series(\n",
    "                    np.array(true) / np.array(n), index=names\n",
    "                )\n",
    "\n",
    "        # feature importances (only if supported by the model)\n",
    "        if feature_importances[0]:\n",
    "            self.feature_importances_ = pd.DataFrame(\n",
    "                feature_importances, index=names, columns=X.columns\n",
    "            )\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _fit_local(\n",
    "        self,\n",
    "        model,\n",
    "        data: pd.DataFrame,\n",
    "        name: Hashable,\n",
    "        focal_x,\n",
    "        model_kwargs: dict,\n",
    "        keep_models: bool,\n",
    "    ) -> tuple:\n",
    "        \"\"\"Fit individual local model\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model : model class\n",
    "            Scikit-learn model class\n",
    "        data : pd.DataFrame\n",
    "            data for training\n",
    "        name : Hashable\n",
    "            group name, matching the index of the focal geometry\n",
    "        model_kwargs : dict\n",
    "            additional keyword arguments for the model init\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            name, fitted model\n",
    "        \"\"\"\n",
    "        if data[\"_y\"].nunique() == 1:\n",
    "            warnings.warn(f\"y at location {name} is invariant.\")\n",
    "        local_model = model(**model_kwargs)\n",
    "        local_model.fit(\n",
    "            X=data.drop(columns=[\"_y\", \"_weight\"]),\n",
    "            y=data[\"_y\"],\n",
    "            sample_weight=data[\"_weight\"],\n",
    "        )\n",
    "        focal_x = pd.DataFrame(\n",
    "            focal_x.reshape(1, -1),\n",
    "            columns=data.columns.drop([\"_y\", \"_weight\"]),\n",
    "            index=[name],\n",
    "        )\n",
    "        focal_proba = pd.Series(\n",
    "            local_model.predict_proba(focal_x).flatten(), index=local_model.classes_\n",
    "        )\n",
    "        output = [\n",
    "            name,\n",
    "            local_model.oob_score_ if self._measure_oob else None,\n",
    "            getattr(local_model, \"feature_importances_\", None),\n",
    "            focal_proba,\n",
    "        ]\n",
    "        if keep_models:\n",
    "            output.append(local_model)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def _accuracy_data(self, true, pred):\n",
    "        return sum(true.flatten() == pred), len(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try with RF Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwrf = GWM(\n",
    "    RandomForestClassifier, bandwidth=250, fixed=False, n_jobs=-1, keep_models=False\n",
    ")\n",
    "gwrf.fit(\n",
    "    gdf.iloc[:, 9:15],\n",
    "    gdf[\"STATE_NAME\"],\n",
    "    gdf.geometry,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global OOB score (accuracy) for the GW model measured based on OOB predictions from individual local trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwrf.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local OOB score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.plot(gwrf.local_oob_score_, legend=True, s=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global score (accuracy) for the GW model measured based on prediction of focals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwrf.score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 scores for the GW model measured based on prediction of focals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwrf.f1_macro, gwrf.f1_micro, gwrf.f1_weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OOB score of the global model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwrf.global_model.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get local feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwrf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.plot(gwrf.feature_importances_[\"HC60\"], legend=True, s=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to global feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwrf.global_model.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try Logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwlr = GWM(\n",
    "    LogisticRegression,\n",
    "    bandwidth=250,\n",
    "    fixed=False,\n",
    "    n_jobs=-1,\n",
    "    keep_models=False,\n",
    "    max_iter=500,\n",
    ")\n",
    "gwlr.fit(\n",
    "    pd.DataFrame(\n",
    "        preprocessing.scale(gdf.iloc[:, 9:15]), columns=gdf.iloc[:, 9:15].columns\n",
    "    ),\n",
    "    gdf[\"STATE_NAME\"],\n",
    "    gdf.geometry,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwlr.score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwlr.f1_macro, gwlr.f1_micro, gwlr.f1_weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define bandwidth search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BandwidthSearch:\n",
    "    \"\"\"Optimal bandwidth search for geographically-weighted models\n",
    "\n",
    "    Minimises one of AIC, AICc, BIC based on prediction probability on focal geometries.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :  model class\n",
    "        Scikit-learn model class\n",
    "    fixed : bool, optional\n",
    "        True for distance based bandwidth and False for adaptive (nearest neighbor) bandwidth, by default False\n",
    "    kernel : str, optional\n",
    "        type of kernel function used to weight observations, by default \"bisquare\"\n",
    "    n_jobs : int, optional\n",
    "        The number of jobs to run in parallel. ``-1`` means using all processors by default ``-1``\n",
    "    fit_global_model : bool, optional\n",
    "        Determines if the global baseline model shall be fitted alognside the geographically weighted.\n",
    "    **kwargs\n",
    "        Additional keyword arguments passed to ``model`` initialisation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        fixed: bool = False,\n",
    "        kernel: str | Callable = \"bisquare\",\n",
    "        n_jobs: int = -1,\n",
    "        search_method: str = \"golden_section\",\n",
    "        criterion: str = \"aic\",\n",
    "        min_bandwidth: int | float | None = None,\n",
    "        max_bandwidth: int | float | None = None,\n",
    "        interval: int | float | None = None,\n",
    "        max_iterations: int = 100,\n",
    "        tolerance: float = 1e-2,\n",
    "        verbose: bool = False,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        self.model = model\n",
    "        self.kernel = kernel\n",
    "        self.fixed = fixed\n",
    "        self.model_kwargs = kwargs\n",
    "        self.n_jobs = n_jobs\n",
    "        self.search_method = search_method\n",
    "        self.criterion = criterion\n",
    "        self.min_bandwidth = min_bandwidth\n",
    "        self.max_bandwidth = max_bandwidth\n",
    "        self.interval = interval\n",
    "        self.max_iterations = max_iterations\n",
    "        self.tolerance = tolerance\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series, geometry: gpd.GeoSeries) -> None:\n",
    "        if self.search_method == \"interval\":\n",
    "            self._interval(X=X, y=y, geometry=geometry)\n",
    "        elif self.search_method == \"golden_section\":\n",
    "            self._golden_section(X=X, y=y, geometry=geometry, tolerance=self.tolerance)\n",
    "\n",
    "        self.optimal_bandwidth = self.oob_scores.idxmin()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _score(\n",
    "        self, X: pd.DataFrame, y: pd.Series, geometry: gpd.GeoSeries, bw: int | float\n",
    "    ) -> float:\n",
    "        \"\"\"Fit the model ans report criterion score.\n",
    "\n",
    "        In case of invariant y in a local model, returns -np.inf\n",
    "        \"\"\"\n",
    "        try:\n",
    "            rf = GWM(\n",
    "                model=self.model,\n",
    "                bandwidth=bw,\n",
    "                fixed=self.fixed,\n",
    "                kernel=self.kernel,\n",
    "                n_jobs=self.n_jobs,\n",
    "                fit_global_model=False,\n",
    "                measure_performance=False,\n",
    "                strict=True,\n",
    "                **self.model_kwargs,\n",
    "            ).fit(X=X, y=y, geometry=geometry)\n",
    "            log_likelihood = -metrics.log_loss(y, rf.focal_proba_)\n",
    "            n, k = X.shape\n",
    "            match self.criterion:\n",
    "                case \"aic\":\n",
    "                    return self._aic(k, n, log_likelihood)\n",
    "                case \"bic\":\n",
    "                    return self._bic(k, n, log_likelihood)\n",
    "                case \"aicc\":\n",
    "                    return self._aicc(k, n, log_likelihood)\n",
    "\n",
    "        except ValueError:  # invariant subset\n",
    "            return np.inf\n",
    "\n",
    "    def _interval(self, X: pd.DataFrame, y: pd.Series, geometry: gpd.GeoSeries) -> None:\n",
    "        \"\"\"Fit models using the equal interval search.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd.DataFrame\n",
    "            Independent variables\n",
    "        y : pd.Series\n",
    "            Dependent variable\n",
    "        geometry : gpd.GeoSeries\n",
    "            Geographic location\n",
    "        \"\"\"\n",
    "        oob_scores = {}\n",
    "        bw = self.min_bandwidth\n",
    "        while bw <= self.max_bandwidth:\n",
    "            self.oob_scores[bw] = self._score(X=X, y=y, geometry=geometry, bw=bw)\n",
    "            if self.verbose:\n",
    "                print(f\"Bandwidth: {bw:.2f}, score: {self.oob_scores[bw]:.2f}\")\n",
    "            bw += self.interval\n",
    "        self.oob_scores = pd.Series(oob_scores, name=\"oob_score\")\n",
    "\n",
    "    def _golden_section(\n",
    "        self, X: pd.DataFrame, y: pd.Series, geometry: gpd.GeoSeries, tolerance: float\n",
    "    ) -> None:\n",
    "        delta = 0.38197\n",
    "        if self.fixed:\n",
    "            pairwise_distance = pdist(geometry.get_coordinates())\n",
    "            min_dist = np.min(pairwise_distance)\n",
    "            max_dist = np.max(pairwise_distance)\n",
    "\n",
    "            a = min_dist / 2.0\n",
    "            c = max_dist * 2.0\n",
    "        else:\n",
    "            a = 40 + 2 * X.shape[1]\n",
    "            c = len(geometry)\n",
    "\n",
    "        if self.min_bandwidth:\n",
    "            a = self.min_bandwidth\n",
    "        if self.max_bandwidth:\n",
    "            c = self.max_bandwidth\n",
    "\n",
    "        b = a + delta * np.abs(c - a)\n",
    "        d = c - delta * np.abs(c - a)\n",
    "\n",
    "        diff = 1.0e9\n",
    "        iters = 0\n",
    "        oob_scores = {}\n",
    "        while diff > tolerance and iters < self.max_iterations and a != np.inf:\n",
    "            if not self.fixed:  # ensure we use int as possible bandwidth\n",
    "                b = int(b)\n",
    "                d = int(d)\n",
    "\n",
    "            if b in oob_scores:\n",
    "                score_b = oob_scores[b]\n",
    "            else:\n",
    "                score_b = self._score(X=X, y=y, geometry=geometry, bw=b)\n",
    "                if self.verbose:\n",
    "                    print(\n",
    "                        f\"Bandwidth: {f'{b:.2f}'.rstrip('0').rstrip('.')}, score: {score_b:.2f}\"\n",
    "                    )\n",
    "                oob_scores[b] = score_b\n",
    "\n",
    "            if d in oob_scores:\n",
    "                score_d = oob_scores[d]\n",
    "            else:\n",
    "                score_d = self._score(X=X, y=y, geometry=geometry, bw=d)\n",
    "                if self.verbose:\n",
    "                    print(\n",
    "                        f\"Bandwidth: {f'{d:.2f}'.rstrip('0').rstrip('.')}, score: {score_d:.2f}\"\n",
    "                    )\n",
    "                oob_scores[d] = score_d\n",
    "\n",
    "            if score_b <= score_d:\n",
    "                c = d\n",
    "                d = b\n",
    "                b = a + delta * np.abs(c - a)\n",
    "\n",
    "            else:\n",
    "                a = b\n",
    "                b = d\n",
    "                d = c - delta * np.abs(c - a)\n",
    "\n",
    "            diff = np.abs(score_b - score_d)\n",
    "\n",
    "        self.oob_scores = pd.Series(oob_scores, name=\"oob_score\")\n",
    "\n",
    "    def _aic(self, k, n, log_likelihood):\n",
    "        return 2 * k - 2 * log_likelihood\n",
    "\n",
    "    def _bic(self, k, n, log_likelihood):\n",
    "        return -2 * log_likelihood + k * np.log(n)\n",
    "\n",
    "    def _aicc(self, k, n, log_likelihood):\n",
    "        return self._aic(k, n, log_likelihood) + 2 * k * (k + 1) / (n - k - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Golden section search with a fixed distance bandwidth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = BandwidthSearch(\n",
    "    RandomForestClassifier,\n",
    "    fixed=True,\n",
    "    n_jobs=-1,\n",
    "    search_method=\"golden_section\",\n",
    "    criterion=\"aic\",\n",
    "    max_iterations=10,\n",
    "    min_bandwidth=250_000,\n",
    "    max_bandwidth=2_000_000,\n",
    "    verbose=True,\n",
    ")\n",
    "search.fit(\n",
    "    gdf.iloc[:, 9:15],\n",
    "    gdf[\"STATE_NAME\"],\n",
    "    gdf.geometry,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the optimal one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.optimal_bandwidth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Golden section search with an adaptive KNN bandwidth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = BandwidthSearch(\n",
    "    LogisticRegression,\n",
    "    fixed=False,\n",
    "    n_jobs=-1,\n",
    "    search_method=\"golden_section\",\n",
    "    criterion=\"aic\",\n",
    "    max_iterations=10,\n",
    "    tolerance=0.1,\n",
    "    verbose=True,\n",
    "    max_iter=500,  # passed to log regr\n",
    ")\n",
    "search.fit(\n",
    "    pd.DataFrame(\n",
    "        preprocessing.scale(gdf.iloc[:, 9:15]), columns=gdf.iloc[:, 9:15].columns\n",
    "    ),\n",
    "    gdf[\"STATE_NAME\"],\n",
    "    gdf.geometry,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the optimal one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.optimal_bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
